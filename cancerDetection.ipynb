{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "0K1oQgdBPpM-",
    "outputId": "63685529-92bb-450a-e255-db595fa53192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from IPython.display import Image\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Shared Input Layer\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Qvq4jng8Pvgy",
    "outputId": "83706997-2929-4683-d64a-2d3643e28147"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
       "0         M        17.99  ...          0.4601                  0.11890\n",
       "1         M        20.57  ...          0.2750                  0.08902\n",
       "2         M        19.69  ...          0.3613                  0.08758\n",
       "3         M        11.42  ...          0.6638                  0.17300\n",
       "4         M        20.29  ...          0.2364                  0.07678\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    dummies = pd.get_dummies(df[target])\n",
    "    return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "path = \"./drive/\"\n",
    "\n",
    "filename = os.path.join(path,\"My Drive/breastCancerDataset.csv\")\n",
    "df = pd.read_csv(filename)\n",
    "df = df.drop(columns=['Unnamed: 32', 'id'])\n",
    "\n",
    "df.head()\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOLSf5tPRXTr"
   },
   "outputs": [],
   "source": [
    "x,y = to_xy(df,\"diagnosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2DHzdBYe7WK"
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x  = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6nc8LaBSWla"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "3O63xlpDdCKJ",
    "outputId": "e1108978-957d-4d80-a036-bc16d4ef7fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0983657  -1.065715   -1.0614318  -0.9479084   0.17504703 -0.24164999\n",
      " -0.6652793  -0.7363962  -0.6521268   1.0281019  -0.24243806  2.3443985\n",
      " -0.23368374 -0.46219167  3.4398131   1.186639   -0.19177078  0.18878981\n",
      "  1.9624041   1.120795   -1.1160071  -1.0091794  -1.0833471  -0.9202376\n",
      "  0.15918623 -0.5767564  -0.962232   -1.1247313  -0.7551084   0.05176861]\n",
      "[1. 0.]\n",
      "(455, 30)\n",
      "(455, 2)\n",
      "(114, 30)\n",
      "(114, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "_W313q05TCti",
    "outputId": "6d4120c3-941e-4cec-ce2b-a849d9b3edb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 6)                 186       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 56        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 302\n",
      "Trainable params: 302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=x_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7MO_6W5STYiu",
    "outputId": "acb3ef69-4f84-49cb-cbaa-4c0c2281ac58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "76/76 - 0s - loss: 0.6767 - val_loss: 0.6348\n",
      "Epoch 2/100\n",
      "76/76 - 0s - loss: 0.6535 - val_loss: 0.6252\n",
      "Epoch 3/100\n",
      "76/76 - 0s - loss: 0.6357 - val_loss: 0.6035\n",
      "Epoch 4/100\n",
      "76/76 - 0s - loss: 0.6042 - val_loss: 0.5668\n",
      "Epoch 5/100\n",
      "76/76 - 0s - loss: 0.5584 - val_loss: 0.5157\n",
      "Epoch 6/100\n",
      "76/76 - 0s - loss: 0.5024 - val_loss: 0.4551\n",
      "Epoch 7/100\n",
      "76/76 - 0s - loss: 0.4357 - val_loss: 0.3895\n",
      "Epoch 8/100\n",
      "76/76 - 0s - loss: 0.3673 - val_loss: 0.3218\n",
      "Epoch 9/100\n",
      "76/76 - 0s - loss: 0.3042 - val_loss: 0.2636\n",
      "Epoch 10/100\n",
      "76/76 - 0s - loss: 0.2505 - val_loss: 0.2146\n",
      "Epoch 11/100\n",
      "76/76 - 0s - loss: 0.2086 - val_loss: 0.1749\n",
      "Epoch 12/100\n",
      "76/76 - 0s - loss: 0.1764 - val_loss: 0.1471\n",
      "Epoch 13/100\n",
      "76/76 - 0s - loss: 0.1526 - val_loss: 0.1243\n",
      "Epoch 14/100\n",
      "76/76 - 0s - loss: 0.1348 - val_loss: 0.1088\n",
      "Epoch 15/100\n",
      "76/76 - 0s - loss: 0.1218 - val_loss: 0.0962\n",
      "Epoch 16/100\n",
      "76/76 - 0s - loss: 0.1114 - val_loss: 0.0865\n",
      "Epoch 17/100\n",
      "76/76 - 0s - loss: 0.1039 - val_loss: 0.0776\n",
      "Epoch 18/100\n",
      "76/76 - 0s - loss: 0.0987 - val_loss: 0.0722\n",
      "Epoch 19/100\n",
      "76/76 - 0s - loss: 0.0921 - val_loss: 0.0664\n",
      "Epoch 20/100\n",
      "76/76 - 0s - loss: 0.0880 - val_loss: 0.0624\n",
      "Epoch 21/100\n",
      "76/76 - 0s - loss: 0.0848 - val_loss: 0.0588\n",
      "Epoch 22/100\n",
      "76/76 - 0s - loss: 0.0817 - val_loss: 0.0558\n",
      "Epoch 23/100\n",
      "76/76 - 0s - loss: 0.0793 - val_loss: 0.0522\n",
      "Epoch 24/100\n",
      "76/76 - 0s - loss: 0.0773 - val_loss: 0.0499\n",
      "Epoch 25/100\n",
      "76/76 - 0s - loss: 0.0750 - val_loss: 0.0472\n",
      "Epoch 26/100\n",
      "76/76 - 0s - loss: 0.0734 - val_loss: 0.0455\n",
      "Epoch 27/100\n",
      "76/76 - 0s - loss: 0.0721 - val_loss: 0.0441\n",
      "Epoch 28/100\n",
      "76/76 - 0s - loss: 0.0708 - val_loss: 0.0427\n",
      "Epoch 29/100\n",
      "76/76 - 0s - loss: 0.0688 - val_loss: 0.0409\n",
      "Epoch 30/100\n",
      "76/76 - 0s - loss: 0.0684 - val_loss: 0.0398\n",
      "Epoch 31/100\n",
      "76/76 - 0s - loss: 0.0670 - val_loss: 0.0389\n",
      "Epoch 32/100\n",
      "76/76 - 0s - loss: 0.0655 - val_loss: 0.0381\n",
      "Epoch 33/100\n",
      "76/76 - 0s - loss: 0.0649 - val_loss: 0.0374\n",
      "Epoch 34/100\n",
      "76/76 - 0s - loss: 0.0641 - val_loss: 0.0361\n",
      "Epoch 35/100\n",
      "76/76 - 0s - loss: 0.0624 - val_loss: 0.0359\n",
      "Epoch 36/100\n",
      "76/76 - 0s - loss: 0.0621 - val_loss: 0.0347\n",
      "Epoch 37/100\n",
      "76/76 - 0s - loss: 0.0612 - val_loss: 0.0337\n",
      "Epoch 38/100\n",
      "76/76 - 0s - loss: 0.0609 - val_loss: 0.0358\n",
      "Epoch 39/100\n",
      "76/76 - 0s - loss: 0.0596 - val_loss: 0.0344\n",
      "Epoch 40/100\n",
      "76/76 - 0s - loss: 0.0593 - val_loss: 0.0336\n",
      "Epoch 41/100\n",
      "76/76 - 0s - loss: 0.0582 - val_loss: 0.0329\n",
      "Epoch 42/100\n",
      "76/76 - 0s - loss: 0.0574 - val_loss: 0.0316\n",
      "Epoch 43/100\n",
      "76/76 - 0s - loss: 0.0572 - val_loss: 0.0322\n",
      "Epoch 44/100\n",
      "76/76 - 0s - loss: 0.0561 - val_loss: 0.0313\n",
      "Epoch 45/100\n",
      "76/76 - 0s - loss: 0.0558 - val_loss: 0.0304\n",
      "Epoch 46/100\n",
      "76/76 - 0s - loss: 0.0552 - val_loss: 0.0303\n",
      "Epoch 47/100\n",
      "76/76 - 0s - loss: 0.0545 - val_loss: 0.0304\n",
      "Epoch 48/100\n",
      "76/76 - 0s - loss: 0.0544 - val_loss: 0.0298\n",
      "Epoch 49/100\n",
      "76/76 - 0s - loss: 0.0536 - val_loss: 0.0302\n",
      "Epoch 50/100\n",
      "76/76 - 0s - loss: 0.0530 - val_loss: 0.0296\n",
      "Epoch 51/100\n",
      "76/76 - 0s - loss: 0.0520 - val_loss: 0.0296\n",
      "Epoch 52/100\n",
      "76/76 - 0s - loss: 0.0517 - val_loss: 0.0297\n",
      "Epoch 53/100\n",
      "76/76 - 0s - loss: 0.0513 - val_loss: 0.0311\n",
      "Epoch 54/100\n",
      "76/76 - 0s - loss: 0.0500 - val_loss: 0.0292\n",
      "Epoch 55/100\n",
      "76/76 - 0s - loss: 0.0503 - val_loss: 0.0291\n",
      "Epoch 56/100\n",
      "76/76 - 0s - loss: 0.0497 - val_loss: 0.0289\n",
      "Epoch 57/100\n",
      "76/76 - 0s - loss: 0.0489 - val_loss: 0.0288\n",
      "Epoch 58/100\n",
      "76/76 - 0s - loss: 0.0485 - val_loss: 0.0287\n",
      "Epoch 59/100\n",
      "76/76 - 0s - loss: 0.0479 - val_loss: 0.0276\n",
      "Epoch 60/100\n",
      "76/76 - 0s - loss: 0.0472 - val_loss: 0.0281\n",
      "Epoch 61/100\n",
      "76/76 - 0s - loss: 0.0469 - val_loss: 0.0294\n",
      "Epoch 62/100\n",
      "76/76 - 0s - loss: 0.0479 - val_loss: 0.0283\n",
      "Epoch 63/100\n",
      "76/76 - 0s - loss: 0.0454 - val_loss: 0.0299\n",
      "Epoch 64/100\n",
      "76/76 - 0s - loss: 0.0451 - val_loss: 0.0296\n",
      "Epoch 65/100\n",
      "76/76 - 0s - loss: 0.0452 - val_loss: 0.0300\n",
      "Epoch 66/100\n",
      "76/76 - 0s - loss: 0.0447 - val_loss: 0.0277\n",
      "Epoch 67/100\n",
      "76/76 - 0s - loss: 0.0455 - val_loss: 0.0292\n",
      "Epoch 68/100\n",
      "76/76 - 0s - loss: 0.0436 - val_loss: 0.0299\n",
      "Epoch 69/100\n",
      "76/76 - 0s - loss: 0.0427 - val_loss: 0.0299\n",
      "Epoch 70/100\n",
      "76/76 - 0s - loss: 0.0423 - val_loss: 0.0291\n",
      "Epoch 71/100\n",
      "76/76 - 0s - loss: 0.0423 - val_loss: 0.0306\n",
      "Epoch 72/100\n",
      "76/76 - 0s - loss: 0.0415 - val_loss: 0.0297\n",
      "Epoch 73/100\n",
      "76/76 - 0s - loss: 0.0412 - val_loss: 0.0288\n",
      "Epoch 74/100\n",
      "76/76 - 0s - loss: 0.0403 - val_loss: 0.0299\n",
      "Epoch 00074: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb93be6a0f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=15, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), verbose=2,callbacks=[monitor], epochs=100, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfroaH6Sf9r2"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "htNOP2Ugf2nM",
    "outputId": "dce81efe-df80-4587-c232-f418d83988ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "# Measure accuracy\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print(\"Final accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "UYpznE01fyBo",
    "outputId": "36a59aee-ff55-4b23-a8fa-ed3b05ea77f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [ 1 38]]\n",
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEmCAYAAAD1FIKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        75\n",
      "           1       1.00      0.97      0.99        39\n",
      "\n",
      "    accuracy                           0.99       114\n",
      "   macro avg       0.99      0.99      0.99       114\n",
      "weighted avg       0.99      0.99      0.99       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "print('Plotting confusion matrix')\n",
    "label = encode_text_index(df,'diagnosis')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,label)\n",
    "plt.show()\n",
    "print(classification_report(y_true, pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
